# GrayScale to Color Image - GAN Model

## Overview
This project implements a Generative Adversarial Network (GAN) model for converting grayscale images to color. It utilizes a UNet generator and PatchGAN discriminator architecture, along with customized loss functions.


### Authors
- [@Pooya Nasiri](https://github.com/PooyaNasiri)
- [@Bahador Mirzazadeh](https://github.com/Baha2rM98)


## Dataset
The dataset used in this project is sourced from [Kaggle](https://www.kaggle.com/datasets/aayush9753/image-colorization-dataset). The images are processed using the CIE-LAB color space.


## Requirements
- Python 3.x
- TensorFlow
- NumPy
- OpenCV
- tqdm
- matplotlib
- scikit-image

## Installation
1. Clone the repository:
   ```bash
   git clone https://github.com/PooyaNasiri/GrayScale2RGB-GAN-Model.git
   ```
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

## Model Architecture

### Generator
- The generator is responsible for transforming grayscale images into colorized versions.
- It employs a UNet architecture, featuring an encoder-decoder structure with skip connections.
- The encoder downsamples the input image to extract features, while the decoder upsamples these features to generate the colorized output.
- Skip connections help preserve spatial information and improve gradient flow.
- The generator utilizes convolutional layers, activation functions (e.g., ReLU), and operations like batch normalization and dropout.

### Discriminator
- The discriminator distinguishes between real color images and fake colorized images generated by the generator.
- A PatchGAN discriminator architecture is commonly employed.
- PatchGAN involves multiple convolutional layers followed by downsampling to produce classification scores for image patches.
- It classifies whether each patch of the input image is real or fake, aggregating results to make a final decision about the entire image.

### Training
- Both the generator and discriminator are trained simultaneously in an adversarial manner.
- The generator aims to produce realistic colorized images to fool the discriminator.
- The discriminator aims to distinguish between real and fake images accurately.
- Customized loss functions, such as adversarial loss and perceptual loss, may be employed to train the model effectively.


## Conclusion

This project successfully transforms grayscale images into vibrant colorized versions using advanced deep learning techniques. By employing a UNet generator, PatchGAN discriminator, and customized loss functions, we achieve impressive colorization results. Moving forward, fine-tuning parameters and exploring alternative architectures could further enhance performance.
